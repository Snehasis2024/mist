launcher_args: {experiment_name: 2022_10_28_mist_csi_prospective,
  script_name: run_scripts/train_mist.py,
  slurm_script: launcher_scripts/generic_slurm.sh, 
  visible_devices: [3],
  launch_method: slurm
}
universal_args:
  _slurm_args:
  - {_num_gpu: 1, cpus-per-task: 8, job-name: ms-train, mem-per-cpu: 10G, time: '1-18:00:00'}

  cache-featurizers: [true]
  dataset-name: [csi2022]

  # Debug
  debug: [false] 
  fp-names:
  - - morgan4096
  num-workers: [8]
  persistent-workers: [false]
  seed: [1,2,3,4,5]

  gpus: [1]
  split-file: [data/paired_spectra/csi2022/splits/prospective_split.csv]
  reshuffle-val: [true]
  split-sizes:
  - [0.95, 0.05, 0.0]
  splitter-name: [preset]

  # Data augmentation
  augment-data: [true]
  augment-prob: [0.5]
  batch-size: [128]
  inten-prob: [0.1]
  remove-prob: [0.5]
  remove-weights: [exp]

  iterative-preds: [growing]
  learning-rate: [0.00077]
  weight-decay: [1.0e-07]

  # Learning
  max-epochs: [600]
  min-lr: [5e-06] 
  scheduler: [false] 
  lr-decay-time: [10000]

  # Model params
  num-heads: [8]
  pairwise-featurization: [true]
  peak-attn-layers: [2]
  refine-layers: [4]
  set-pooling: [cls]
  spectra-dropout: [0.1]
  single-form-encoder: [true]
  recycle-form-encoder: [true]
  use-cls: [true]
  cls-type: [ms1]

  # Magma args
  magma-aux-loss: [true]
  frag-fps-loss-lambda: [8]
  magma-modulo: [512]
  patience: [20] 

iterative_args:
  - iterative-preds: [growing]
    iterative-loss-weight: [0.4]
    loss-fn: [cosine]
    hidden-size: [256]

    # LR
    learning-rate: [0.00077]
    lr-decay-time: [10000] 
    lr-decay-frac: [0.95]

    # High batch cosine
    batch-size: [128] 

    # adding forward specs
    add-forward-specs: [true]
    forward-aug-folder: [data/paired_spectra/csi2022/csi_spec_preds_fold_prospective/]
    frac-orig: [0.6]
